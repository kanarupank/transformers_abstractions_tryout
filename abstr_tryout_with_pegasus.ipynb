{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "784b6f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/transformers\n",
      "  Cloning https://github.com/huggingface/transformers to c:\\users\\lenovo\\appdata\\local\\temp\\pip-req-build-vdai8qqw\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Requirement already satisfied: requests in c:\\users\\lenovo\\dip\\nlp\\lib\\site-packages (from transformers==4.6.0.dev0) (2.25.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\lenovo\\dip\\nlp\\lib\\site-packages (from transformers==4.6.0.dev0) (2021.4.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\lenovo\\dip\\nlp\\lib\\site-packages (from transformers==4.6.0.dev0) (20.9)\n",
      "Collecting huggingface-hub==0.0.8\n",
      "  Downloading huggingface_hub-0.0.8-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\lenovo\\dip\\nlp\\lib\\site-packages (from transformers==4.6.0.dev0) (4.60.0)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in c:\\users\\lenovo\\dip\\nlp\\lib\\site-packages (from transformers==4.6.0.dev0) (0.10.2)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\lenovo\\dip\\nlp\\lib\\site-packages (from transformers==4.6.0.dev0) (0.0.45)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\lenovo\\dip\\nlp\\lib\\site-packages (from transformers==4.6.0.dev0) (1.19.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\lenovo\\dip\\nlp\\lib\\site-packages (from transformers==4.6.0.dev0) (3.0.12)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\lenovo\\dip\\nlp\\lib\\site-packages (from packaging->transformers==4.6.0.dev0) (2.4.7)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\lenovo\\dip\\nlp\\lib\\site-packages (from requests->transformers==4.6.0.dev0) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\lenovo\\dip\\nlp\\lib\\site-packages (from requests->transformers==4.6.0.dev0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\dip\\nlp\\lib\\site-packages (from requests->transformers==4.6.0.dev0) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\lenovo\\dip\\nlp\\lib\\site-packages (from requests->transformers==4.6.0.dev0) (1.26.4)\n",
      "Requirement already satisfied: six in c:\\users\\lenovo\\dip\\nlp\\lib\\site-packages (from sacremoses->transformers==4.6.0.dev0) (1.15.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\lenovo\\dip\\nlp\\lib\\site-packages (from sacremoses->transformers==4.6.0.dev0) (1.0.1)\n",
      "Requirement already satisfied: click in c:\\users\\lenovo\\dip\\nlp\\lib\\site-packages (from sacremoses->transformers==4.6.0.dev0) (7.1.2)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (PEP 517): started\n",
      "  Building wheel for transformers (PEP 517): finished with status 'done'\n",
      "  Created wheel for transformers: filename=transformers-4.6.0.dev0-py3-none-any.whl size=2212984 sha256=04882dce93544e16cf871bf7b644c6e007cffaf7a3c5be69f018c7847b26a4ca\n",
      "  Stored in directory: C:\\Users\\Lenovo\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-g_pmwkb8\\wheels\\14\\a0\\7b\\8f6b25ba4110aa215fcb8d6aedd6cd4f9b9b6619190999ac2b\n",
      "Successfully built transformers\n",
      "Installing collected packages: huggingface-hub, transformers\n",
      "  Attempting uninstall: transformers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/huggingface/transformers 'C:\\Users\\Lenovo\\AppData\\Local\\Temp\\pip-req-build-vdai8qqw'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found existing installation: transformers 4.5.1\n",
      "    Uninstalling transformers-4.5.1:\n",
      "      Successfully uninstalled transformers-4.5.1\n",
      "Successfully installed huggingface-hub-0.0.8 transformers-4.6.0.dev0\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b209822",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install SentencePiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75891011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.6.0.dev0\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4a8d367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a39b86aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "079b4f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "src_text = [\"first of all i will explain my csv file. Here I have three inputs with datetime. Here I measured value not in exact time per hour. It is jumbled. So first what I did , make all data to display with in every one hour. After writing that code, it is displayed in evry hour data as above. then the data is append value mix with datetime. Then according to that data I want to predict value. This is what I am trying to do ?\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d295eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='google/pegasus-reddit_tifu'\n",
    "torch_device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "tokenizer=PegasusTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model=PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n",
    "\n",
    "batch=tokenizer.prepare_seq2seq_batch(src_text, truncation=True, padding='longest', return_tensors='pt').to(torch_device)\n",
    "\n",
    "translated=model.generate(**batch)\n",
    "tgt_text=tokenizer.batch_decode(translated, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5743e28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: i am trying to predict value with datetime and append value mix with datetime. then according to that data i want to predict value. this is what i am trying to do? this is what i am trying to do? this is what i am trying to do? this is what i am trying to do? this is what i am trying to do? this is what i am trying to do? this is what i am trying to do? this is what i am trying to do? this is what i am trying to do? this is what i am trying to do\n"
     ]
    }
   ],
   "source": [
    "print('Summary:', tgt_text[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
